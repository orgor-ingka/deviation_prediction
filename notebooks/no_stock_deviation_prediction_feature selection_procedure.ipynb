{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d2758cc",
   "metadata": {},
   "source": [
    "* Author: Niclas Lavesson\n",
    "* Date: 2026-01-15\n",
    "* Description: This notebook runs code that create a composite score for what features to include in the predictive model. Six methods are used to create the composite score\n",
    "* METHOD 1: Variance Threshold\n",
    "* METHOD 2: SelectKBest with F-test\n",
    "* METHOD 3: Mutual Information\n",
    "* METHOD 4: Random Forest Feature Importance\n",
    "* METHOD 5: Recursive Feature Elimination (RFE)\n",
    "* METHOD 6: L1-based Selection (Lasso)\n",
    "\n",
    "By examining the curve of the composite scores it is possible to see where the number of features (and which) that have less explantory/or predictive power. This information is saved in an xlsx-file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1e4d2d",
   "metadata": {},
   "source": [
    "# Loading data from BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2755d768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing BigQuery query for table: ingka-ff-somdata-prod.OMDA_Analytics.no_stock_prediction_train_data_reduced\n",
      "Executing BigQuery query for table: ingka-ff-somdata-prod.OMDA_Analytics.no_stock_prediction_test_data_reduced\n",
      "DataFrames loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery as bq\n",
    "import pandas as pd\n",
    "\n",
    "bq_client = bq.Client()\n",
    "\n",
    "def load_bq_table_to_dataframe(table_path: str):\n",
    "    \"\"\"\n",
    "    Loads data from a specified BigQuery table into a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        table_path (str): The full path to the BigQuery table (e.g., 'project.dataset.table').\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the data from the BigQuery table.\n",
    "    \"\"\"\n",
    "    query_string = f\"SELECT * FROM `{table_path}`\"\n",
    "    print(f\"Executing BigQuery query for table: {table_path}\")\n",
    "    bq_query_job = bq_client.query(query_string, job_config=bq.QueryJobConfig())\n",
    "    return bq_query_job.to_dataframe()\n",
    "\n",
    "# Define the table paths (as strings)\n",
    "base_path = 'ingka-ff-somdata-prod.OMDA_Analytics'\n",
    "train_table_path = f'{base_path}.no_stock_prediction_train_data_reduced'\n",
    "test_table_path = f'{base_path}.no_stock_prediction_test_data_reduced'\n",
    "\n",
    "# Load data frames\n",
    "merged_train_data = load_bq_table_to_dataframe(train_table_path)\n",
    "merged_test_data = load_bq_table_to_dataframe(test_table_path)\n",
    "\n",
    "print(\"DataFrames loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695a24e4",
   "metadata": {},
   "source": [
    "## Create X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "084ad838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "y_train created. Shape: (1416764,)\n",
      "X_train created. Shape: (1416764, 125)\n",
      "\n",
      "y_test created. Shape: (354192,)\n",
      "X_test created. Shape: (354192, 125)\n",
      "\n",
      "--- X_train Head ---\n",
      "   sl3_ordered_qty  average_daily_stock_change_rate  \\\n",
      "0         0.288102                         0.274346   \n",
      "1        -0.319347                         0.260025   \n",
      "2        -0.319347                        -1.222145   \n",
      "3         0.136239                         0.260025   \n",
      "4         1.047412                         0.328351   \n",
      "\n",
      "   average_daily_stock_change_rate_replenishment  \\\n",
      "0                                      -0.224212   \n",
      "1                                      -0.132106   \n",
      "2                                       0.548648   \n",
      "3                                       0.398681   \n",
      "4                                      -0.128225   \n",
      "\n",
      "   current_daily_stock_change_rate  customer_type_PRIVATE  \\\n",
      "0                        -0.014684                    1.0   \n",
      "1                         0.222302                    1.0   \n",
      "2                        -0.647487                    1.0   \n",
      "3                         1.427402                    1.0   \n",
      "4                         0.005485                    1.0   \n",
      "\n",
      "   customer_type_Unknown  days_since_last_replenishment  \\\n",
      "0                    0.0                      -0.297576   \n",
      "1                    0.0                      -0.297576   \n",
      "2                    0.0                      -0.217715   \n",
      "3                    0.0                      -0.297576   \n",
      "4                    0.0                       0.980205   \n",
      "\n",
      "   days_since_last_stockout  item_name_count  line_total_euros  ...  \\\n",
      "0                 -1.229128            184.0         -0.494073  ...   \n",
      "1                  1.341227            383.0         -0.143631  ...   \n",
      "2                 -0.257053            797.0         -0.294221  ...   \n",
      "3                 -0.541030           6244.0         -0.414845  ...   \n",
      "4                  0.117942         498476.0          0.181618  ...   \n",
      "\n",
      "   ship_node_stock_related_deviation_rate_1month  sl1_ordered_qty  \\\n",
      "0                                      -0.630890        -0.178455   \n",
      "1                                       0.061029        -0.178455   \n",
      "2                                       0.638649        -0.178455   \n",
      "3                                      -0.572220        -0.178455   \n",
      "4                                      -0.465083        -0.178455   \n",
      "\n",
      "   sl2_ordered_qty  sl4_ordered_qty  stock_variance_4_weeks  \\\n",
      "0        -0.257688         -0.25633               -0.074177   \n",
      "1        -0.078490         -0.25633               -0.073710   \n",
      "2         1.175893         -0.25633               -0.055035   \n",
      "3        -0.257688         -0.25633               -0.067916   \n",
      "4        -0.257688         -0.25633               -0.074626   \n",
      "\n",
      "   stockout_count_28_days  time_in_status_mins  time_to_dispatch_date_mins  \\\n",
      "0                0.335622            18.341170                    0.005787   \n",
      "1               -0.246722             0.826139                    0.013744   \n",
      "2               -0.246722            -0.169054                    0.006303   \n",
      "3               -0.246722            -0.091408                    0.012300   \n",
      "4               -0.246722            -0.169044                    0.003307   \n",
      "\n",
      "   time_to_min_notification_date_mins  time_to_promised_appt_start_date_mins  \n",
      "0                            0.563723                               1.775952  \n",
      "1                           -0.318680                               2.584534  \n",
      "2                            0.776680                               0.342563  \n",
      "3                            2.997348                               2.032230  \n",
      "4                           -0.419529                              -0.440220  \n",
      "\n",
      "[5 rows x 125 columns]\n",
      "\n",
      "--- y_train Head ---\n",
      "0    1.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "Name: deviation, dtype: float64\n",
      "\n",
      "--- X_test Head ---\n",
      "   sl3_ordered_qty  average_daily_stock_change_rate  \\\n",
      "0        -0.015623                         0.213081   \n",
      "1        -0.319347                         0.260025   \n",
      "2        -0.319347                         0.260025   \n",
      "3        -0.319347                         0.188309   \n",
      "4         0.136239                         0.270386   \n",
      "\n",
      "   average_daily_stock_change_rate_replenishment  \\\n",
      "0                                      -0.033645   \n",
      "1                                       1.724173   \n",
      "2                                      -0.056533   \n",
      "3                                      -0.090186   \n",
      "4                                      -0.097272   \n",
      "\n",
      "   current_daily_stock_change_rate  customer_type_PRIVATE  \\\n",
      "0                        -0.027290                   True   \n",
      "1                         1.318993                   True   \n",
      "2                         0.060950                   True   \n",
      "3                        -0.024768                   True   \n",
      "4                        -0.017205                  False   \n",
      "\n",
      "   customer_type_Unknown  days_since_last_replenishment  \\\n",
      "0                  False                       0.261453   \n",
      "1                  False                      -0.217715   \n",
      "2                  False                      -0.297576   \n",
      "3                  False                      -0.217715   \n",
      "4                  False                      -0.137853   \n",
      "\n",
      "   days_since_last_stockout  item_name_count  line_total_euros  ...  \\\n",
      "0                 -1.127187              173         -0.465777  ...   \n",
      "1                 -0.191520              218         -0.460118  ...   \n",
      "2                 -1.054373           498476         -0.279026  ...   \n",
      "3                 -1.101702              435         -0.165843  ...   \n",
      "4                 -0.966995           498476         -0.279026  ...   \n",
      "\n",
      "   ship_node_stock_related_deviation_rate_1month  sl1_ordered_qty  \\\n",
      "0                                       -0.66236        -0.178455   \n",
      "1                                       -0.66236        -0.178455   \n",
      "2                                       -0.66236        -0.178455   \n",
      "3                                       -0.66236        -0.178455   \n",
      "4                                       -0.66236        -0.178455   \n",
      "\n",
      "   sl2_ordered_qty  sl4_ordered_qty  stock_variance_4_weeks  \\\n",
      "0        -0.257688        -0.046857               -0.073193   \n",
      "1         0.817498        -0.256330                0.117636   \n",
      "2         0.279905        -0.256330               -0.074648   \n",
      "3         0.279905        -0.256330               -0.074515   \n",
      "4        -0.257688        -0.256330               -0.074389   \n",
      "\n",
      "   stockout_count_28_days  time_in_status_mins  time_to_dispatch_date_mins  \\\n",
      "0                0.335622            -0.169070                    0.004032   \n",
      "1               -0.246722            -0.169070                    0.004032   \n",
      "2               -0.246722            -0.169070                    0.004032   \n",
      "3               -0.246722            -0.169070                    0.004032   \n",
      "4               -0.246722            -0.169054                    0.004032   \n",
      "\n",
      "   time_to_min_notification_date_mins  time_to_promised_appt_start_date_mins  \n",
      "0                           -0.133868                              -0.348531  \n",
      "1                           -0.133868                              -0.348531  \n",
      "2                           -0.133868                              -0.348531  \n",
      "3                           -0.133868                              -0.348531  \n",
      "4                           -0.133874                              -0.348536  \n",
      "\n",
      "[5 rows x 125 columns]\n",
      "\n",
      "--- y_test Head ---\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "Name: deviation, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Define the list of feature columns\n",
    "feature_cols = [col for col in merged_train_data.columns if col != 'deviation']\n",
    "\n",
    "# 1. Create y_train from merged_train_data\n",
    "y_train = merged_train_data['deviation'].copy()\n",
    "print(f\"\\ny_train created. Shape: {y_train.shape}\")\n",
    "\n",
    "# 2. Create X_train from merged_train_data\n",
    "# Ensure all feature_cols exist in merged_train_data\n",
    "missing_train_cols = [col for col in feature_cols if col not in merged_train_data.columns]\n",
    "if missing_train_cols:\n",
    "    print(f\"Warning: The following feature columns are missing from merged_train_data: {missing_train_cols}\")\n",
    "    # Filter feature_cols to only include those present in the DataFrame\n",
    "    X_train_cols = [col for col in feature_cols if col in merged_train_data.columns]\n",
    "    X_train = merged_train_data[X_train_cols].copy()\n",
    "else:\n",
    "    X_train = merged_train_data[feature_cols].copy()\n",
    "print(f\"X_train created. Shape: {X_train.shape}\")\n",
    "\n",
    "# 3. Create y_test from merged_test_data\n",
    "y_test = merged_test_data['deviation'].copy()\n",
    "print(f\"\\ny_test created. Shape: {y_test.shape}\")\n",
    "\n",
    "# 4. Create X_test from merged_test_data\n",
    "# Ensure all feature_cols exist in merged_test_data\n",
    "missing_test_cols = [col for col in feature_cols if col not in merged_test_data.columns]\n",
    "if missing_test_cols:\n",
    "    print(f\"Warning: The following feature columns are missing from merged_test_data: {missing_test_cols}\")\n",
    "    # Filter feature_cols to only include those present in the DataFrame\n",
    "    X_test_cols = [col for col in feature_cols if col in merged_test_data.columns]\n",
    "    X_test = merged_test_data[X_test_cols].copy()\n",
    "else:\n",
    "    X_test = merged_test_data[feature_cols].copy()\n",
    "print(f\"X_test created. Shape: {X_test.shape}\")\n",
    "\n",
    "# Display the first few rows of the created DataFrames to verify\n",
    "print(\"\\n--- X_train Head ---\")\n",
    "print(X_train.head())\n",
    "print(\"\\n--- y_train Head ---\")\n",
    "print(y_train.head())\n",
    "print(\"\\n--- X_test Head ---\")\n",
    "print(X_test.head())\n",
    "print(\"\\n--- y_test Head ---\")\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46617ece",
   "metadata": {},
   "source": [
    "# Running feature selection procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6dd68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import (\n",
    "    VarianceThreshold,\n",
    "    SelectKBest,\n",
    "    f_classif,\n",
    "    mutual_info_classif,\n",
    "    RFE,\n",
    "    SelectFromModel\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"AUTOMATED FEATURE SELECTION PIPELINE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nInitial number of features: {X_train.shape[1]}\")\n",
    "print(f\"Number of training samples: {X_train.shape[0]}\")\n",
    "print(f\"Number of test samples: {X_test.shape[0]}\")\n",
    "\n",
    "# Store feature names\n",
    "feature_names = X_train.columns.tolist()\n",
    "\n",
    "# Initialize results dictionary\n",
    "feature_scores = {}\n",
    "\n",
    "# ==================================================================================\n",
    "# METHOD 1: Variance Threshold\n",
    "# ==================================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METHOD 1: VARIANCE THRESHOLD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "selector_var = VarianceThreshold(threshold=0.01)\n",
    "selector_var.fit(X_train)\n",
    "var_features = X_train.columns[selector_var.get_support()].tolist()\n",
    "\n",
    "print(f\"Features passing variance threshold: {len(var_features)}/{len(feature_names)}\")\n",
    "feature_scores['variance'] = {feat: 1 if feat in var_features else 0 for feat in feature_names}\n",
    "\n",
    "# ==================================================================================\n",
    "# METHOD 2: SelectKBest with F-test\n",
    "# ==================================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METHOD 2: SELECTKBEST (F-TEST)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "k_best = min(50, X_train.shape[1])\n",
    "selector_kbest = SelectKBest(f_classif, k=k_best)\n",
    "selector_kbest.fit(X_train, y_train)\n",
    "\n",
    "kbest_scores = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'score': selector_kbest.scores_\n",
    "}).sort_values('score', ascending=False)\n",
    "\n",
    "print(f\"Top 10 features by F-test:\")\n",
    "print(kbest_scores.head(10))\n",
    "\n",
    "feature_scores['f_test'] = dict(zip(kbest_scores['feature'], kbest_scores['score']))\n",
    "\n",
    "# ==================================================================================\n",
    "# METHOD 3: Mutual Information\n",
    "# ==================================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METHOD 3: MUTUAL INFORMATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "mi_scores = mutual_info_classif(X_train, y_train, random_state=42)\n",
    "mi_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'score': mi_scores\n",
    "}).sort_values('score', ascending=False)\n",
    "\n",
    "print(f\"Top 10 features by Mutual Information:\")\n",
    "print(mi_df.head(10))\n",
    "\n",
    "feature_scores['mutual_info'] = dict(zip(mi_df['feature'], mi_df['score']))\n",
    "\n",
    "# ==================================================================================\n",
    "# METHOD 4: Random Forest Feature Importance\n",
    "# ==================================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METHOD 4: RANDOM FOREST FEATURE IMPORTANCE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "rf_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"Top 10 features by Random Forest:\")\n",
    "print(rf_importance.head(10))\n",
    "\n",
    "feature_scores['random_forest'] = dict(zip(rf_importance['feature'], rf_importance['importance']))\n",
    "\n",
    "# ==================================================================================\n",
    "# METHOD 5: Recursive Feature Elimination (RFE)\n",
    "# ==================================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METHOD 5: RECURSIVE FEATURE ELIMINATION (RFE)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "n_features_rfe = min(30, X_train.shape[1])\n",
    "estimator = LogisticRegression(solver='liblinear', random_state=42, max_iter=1000)\n",
    "rfe_selector = RFE(estimator, n_features_to_select=n_features_rfe, step=1)\n",
    "rfe_selector.fit(X_train, y_train)\n",
    "\n",
    "rfe_ranking = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'ranking': rfe_selector.ranking_\n",
    "}).sort_values('ranking')\n",
    "\n",
    "print(f\"Top 10 features by RFE:\")\n",
    "print(rfe_ranking.head(10))\n",
    "\n",
    "# Convert ranking to score (lower rank = higher score)\n",
    "max_rank = rfe_ranking['ranking'].max()\n",
    "feature_scores['rfe'] = {feat: (max_rank - rank + 1) for feat, rank in zip(rfe_ranking['feature'], rfe_ranking['ranking'])}\n",
    "\n",
    "# ==================================================================================\n",
    "# METHOD 6: L1-based Selection (Lasso)\n",
    "# ==================================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METHOD 6: L1-BASED SELECTION (LOGISTIC REGRESSION)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "l1_model = LogisticRegression(penalty='l1', solver='liblinear', C=0.1, random_state=42, max_iter=1000)\n",
    "l1_selector = SelectFromModel(l1_model, prefit=False)\n",
    "l1_selector.fit(X_train, y_train)\n",
    "\n",
    "l1_features = X_train.columns[l1_selector.get_support()].tolist()\n",
    "print(f\"Features selected by L1: {len(l1_features)}/{len(feature_names)}\")\n",
    "\n",
    "feature_scores['l1_selection'] = {feat: 1 if feat in l1_features else 0 for feat in feature_names}\n",
    "\n",
    "# ==================================================================================\n",
    "# AGGREGATE RESULTS\n",
    "# ==================================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGGREGATING RESULTS FROM ALL METHODS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create a comprehensive DataFrame\n",
    "results_df = pd.DataFrame(feature_scores).fillna(0)\n",
    "\n",
    "# Normalize scores to 0-1 range for each method\n",
    "for col in results_df.columns:\n",
    "    max_val = results_df[col].max()\n",
    "    if max_val > 0:\n",
    "        results_df[col] = results_df[col] / max_val\n",
    "\n",
    "# Calculate consensus score (average across all methods)\n",
    "results_df['consensus_score'] = results_df.mean(axis=1)\n",
    "results_df['feature'] = feature_names\n",
    "results_df = results_df.sort_values('consensus_score', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 features by consensus score:\")\n",
    "print(results_df[['feature', 'consensus_score']].head(20))\n",
    "\n",
    "# ==================================================================================\n",
    "# SELECT FINAL FEATURES\n",
    "# ==================================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SELECTING FINAL FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# You can adjust top_n to select how many features you want\n",
    "top_n = 30  # Adjust this number based on your needs\n",
    "selected_features = results_df.head(top_n)['feature'].tolist()\n",
    "\n",
    "print(f\"\\nSelected {len(selected_features)} features:\")\n",
    "for i, feat in enumerate(selected_features, 1):\n",
    "    score = results_df[results_df['feature'] == feat]['consensus_score'].values[0]\n",
    "    print(f\"  {i}. {feat}: {score:.4f}\")\n",
    "\n",
    "# ==================================================================================\n",
    "# TRANSFORM DATASETS\n",
    "# ==================================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRANSFORMING DATASETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "X_train_selected = X_train[selected_features].copy()\n",
    "X_test_selected = X_test[selected_features].copy()\n",
    "\n",
    "print(f\"\\nOriginal X_train shape: {X_train.shape}\")\n",
    "print(f\"Selected X_train shape: {X_train_selected.shape}\")\n",
    "print(f\"Original X_test shape: {X_test.shape}\")\n",
    "print(f\"Selected X_test shape: {X_test_selected.shape}\")\n",
    "\n",
    "# ==================================================================================\n",
    "# SAVE RESULTS\n",
    "# ==================================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "output_filename = 'feature_selection_comprehensive_results.xlsx'\n",
    "output_path = f'C:/Users/NILAV/OneDrive - IKEA/Documents/Project folder/NO STOCK deviation predictions/Feature engineering/{output_filename}'\n",
    "\n",
    "# Reorder columns for better readability\n",
    "cols_order = ['feature', 'consensus_score'] + [col for col in results_df.columns if col not in ['feature', 'consensus_score']]\n",
    "results_df_export = results_df[cols_order]\n",
    "\n",
    "results_df_export.to_excel(output_path, index=False)\n",
    "print(f\"\\nResults saved to '{output_filename}'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… AUTOMATED FEATURE SELECTION COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nYou can now use X_train_selected and X_test_selected for model training.\")\n",
    "print(f\"Selected features are stored in the 'selected_features' list.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df650e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, len(results_df) + 1), results_df['consensus_score'].values, marker='o')\n",
    "plt.xlabel('Feature Rank')\n",
    "plt.ylabel('Consensus Score')\n",
    "plt.title('Consensus Score by Feature Rank (Look for the \"Elbow\")')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', label='Example threshold: 0.5')\n",
    "plt.axhline(y=0.3, color='orange', linestyle='--', label='Example threshold: 0.3')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
